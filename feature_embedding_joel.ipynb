{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = '../datathon-fme-mango/archive/'\n",
    "imagepath = dirpath + 'images/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:46<00:00,  9.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate embeddings for each image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "EMBEDDING_DIM = 1024\n",
    "\n",
    "# load the model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "model.eval()\n",
    "\n",
    "# load the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# load the image\n",
    "def load_image(imagepath):\n",
    "    image = Image.open(imagepath)\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "# generate the embedding\n",
    "def generate_embedding(imagepath):\n",
    "    image = load_image(imagepath)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(image)\n",
    "    return embedding\n",
    "\n",
    "NUM_IM = 1000\n",
    "\n",
    "# generate the embeddings for all images\n",
    "imagepaths = []\n",
    "embeddings = {}\n",
    "for image in tqdm(os.listdir(imagepath)[:NUM_IM]):\n",
    "    try:\n",
    "        imagepaths.append(image)\n",
    "        embedding = generate_embedding(imagepath + image)\n",
    "        embeddings[image] = embedding\n",
    "    except:\n",
    "        print(f'Error with {image}')\n",
    "\n",
    "# save the embeddings\n",
    "embeddings = {k: v.numpy().flatten() for k, v in embeddings.items()}\n",
    "# save as pickle\n",
    "with open('embeddings/embeddings_resnet50.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
